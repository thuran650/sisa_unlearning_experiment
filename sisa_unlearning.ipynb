{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "314180b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)            # Python random\n",
    "    np.random.seed(seed)         # NumPy\n",
    "    torch.manual_seed(seed)      # CPU seed\n",
    "\n",
    "    # For GPU (CUDA)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # For MPS (Apple Silicon)\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch.mps.manual_seed(seed)\n",
    "\n",
    "    # Make CuDNN deterministic (if using CUDA)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5127694c",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "65fc6648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "set_seed(42)\n",
    "class ShardDataset(Dataset):\n",
    "    def __init__(self, shard_path, transform=None):\n",
    "        \"\"\"\n",
    "        shard_path: path to a single shard folder\n",
    "        transform: torchvision transforms\n",
    "        \"\"\"\n",
    "        self.shard_path = Path(shard_path)\n",
    "        self.samples = []\n",
    "\n",
    "        # read all images\n",
    "        for class_folder in self.shard_path.iterdir():\n",
    "            if class_folder.is_dir():\n",
    "                for img_path in class_folder.iterdir():\n",
    "                    if img_path.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "                        self.samples.append((img_path, class_folder.name))\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "dc778a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shard 0 size: 900 images\n",
      "Shard 1 size: 900 images\n",
      "Shard 2 size: 850 images\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# transforms for all shards\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "num_shards = 3\n",
    "shard_loaders = []\n",
    "\n",
    "set_seed(42)\n",
    "for shard_idx in range(num_shards):\n",
    "    shard_path = f\"shards/shard_{shard_idx}\"\n",
    "    dataset = ShardDataset(shard_path, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=50, shuffle=True)\n",
    "    shard_loaders.append(loader)\n",
    "    print(f\"Shard {shard_idx} size: {len(dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2b0e8434",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FullDataset(Dataset):\n",
    "    def __init__(self, shards_dir, transform=None):\n",
    "        \"\"\"\n",
    "        shards_dir: path to the parent folder containing all shards\n",
    "        transform: torchvision transforms\n",
    "        \"\"\"\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        shards_dir = Path(shards_dir)\n",
    "\n",
    "        # iterate all shards and all class folders\n",
    "        for shard_folder in shards_dir.iterdir():\n",
    "            if shard_folder.is_dir():\n",
    "                for class_folder in shard_folder.iterdir():\n",
    "                    if class_folder.is_dir():\n",
    "                        for img_path in class_folder.iterdir():\n",
    "                            if img_path.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "                                # store (path, class_name)\n",
    "                                self.samples.append((img_path, class_folder.name))\n",
    "\n",
    "        # build class->index mapping\n",
    "        class_names = sorted({cls for _, cls in self.samples})\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label_idx = self.class_to_idx[label]\n",
    "        return img, label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e09e6552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset size: 2650\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "set_seed(42)\n",
    "full_dataset = FullDataset(shards_dir=\"shards\", transform=transform)\n",
    "full_loader = DataLoader(full_dataset, batch_size=32, shuffle=True)\n",
    "full_test_loader = DataLoader(full_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "print(f\"Full dataset size: {len(full_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dece709",
   "metadata": {},
   "source": [
    "# SISA Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "03e4b46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {'cat': 0, 'dog': 1, 'horse': 2}\n",
      "\n",
      "Training model for shard 0\n",
      "Shard Training Time: 176.06704 seconds\n",
      "Total Training Time: 176.06704 seconds\n",
      "\n",
      "Training model for shard 1\n",
      "Shard Training Time: 96.21077 seconds\n",
      "Total Training Time: 96.21077 seconds\n",
      "\n",
      "Training model for shard 2\n",
      "Shard Training Time: 88.92099 seconds\n",
      "Total Training Time: 88.92099 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import os\n",
    "import time\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "num_classes = 3  # your dataset\n",
    "\n",
    "# Example: small CNN\n",
    "def get_model():\n",
    "    set_seed(42)\n",
    "    model = models.resnet18(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "shard_models = []\n",
    "\n",
    "class_names = sorted([p.name for p in Path(\"shards/shard_0\").iterdir() if p.is_dir()])\n",
    "class_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
    "print(\"Class mapping:\", class_to_idx)\n",
    "\n",
    "subfolder_path = \"my_models/\"\n",
    "\n",
    "start_time = time.time()\n",
    "set_seed(42)\n",
    "for shard_idx, loader in enumerate(shard_loaders):\n",
    "    start = time.time()\n",
    "\n",
    "    print(f\"\\nTraining model for shard {shard_idx}\")\n",
    "    model = get_model()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # simple epoch loop\n",
    "    for epoch in range(n_epochs):  # small number of epochs for demo\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            # convert string labels to integers\n",
    "            labels_idx = torch.tensor([class_to_idx[lbl] for lbl in labels], dtype=torch.long).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels_idx)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    shard_models.append(model)\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Shard Training Time: {end - start:.5f} seconds\")\n",
    "    name = \"model_\"+ str(shard_idx) + \".pt\"\n",
    "    full_path = os.path.join(subfolder_path, name)\n",
    "    torch.save(model.state_dict(), full_path)\n",
    "    print(f\"Total Training Time: {end - start:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac579133",
   "metadata": {},
   "source": [
    "## Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "0c5d1c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def ensemble_predict(models, input_tensor, device):\n",
    "    \"\"\"\n",
    "    models: list of shard models\n",
    "    input_tensor: batch of images (already on device)\n",
    "    returns: ensemble predictions (argmax over average logits)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        outputs = []\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            model.to(device)\n",
    "            outputs.append(model(input_tensor))\n",
    "        avg_output = sum(outputs)\n",
    "        # avg_output = sum(outputs) / len(outputs)\n",
    "        preds = avg_output.argmax(dim=1)\n",
    "    return preds\n",
    "\n",
    "def evaluate_ensemble(shard_models, test_loader, class_names, device):\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    # overall accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # class-wise tracking\n",
    "    class_correct = torch.zeros(num_classes)\n",
    "    class_total   = torch.zeros(num_classes)\n",
    "\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = ensemble_predict(shard_models, imgs, device)\n",
    "\n",
    "        # overall accuracy\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # class-wise accuracy\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i].item()\n",
    "            class_total[label] += 1\n",
    "            if preds[i].item() == label:\n",
    "                class_correct[label] += 1\n",
    "\n",
    "    # overall accuracy\n",
    "    overall_acc = 100 * correct / total\n",
    "\n",
    "    # per-class accuracy\n",
    "    class_acc = {}\n",
    "    for i in range(num_classes):\n",
    "        acc = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
    "        class_acc[class_names[i]] = acc.item()\n",
    "\n",
    "    return overall_acc, class_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ad5b1ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SISA Ensemble Accuracy: 67.77%\n",
      "\n",
      "Class-by-Class Accuracy:\n",
      "cat: 48.71%\n",
      "dog: 76.00%\n",
      "horse: 77.56%\n"
     ]
    }
   ],
   "source": [
    "overall, per_class = evaluate_ensemble(shard_models, full_test_loader, class_names, device)\n",
    "\n",
    "print(f\"SISA Ensemble Accuracy: {overall:.2f}%\\n\")\n",
    "print(\"Class-by-Class Accuracy:\")\n",
    "for cls, acc in per_class.items():\n",
    "    print(f\"{cls}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "14d27f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SISA Ensemble Accuracy: 60.04%\n",
      "\n",
      "Class-by-Class Accuracy:\n",
      "cat: 11.41%\n",
      "dog: 91.67%\n",
      "horse: 74.33%\n"
     ]
    }
   ],
   "source": [
    "# remove entire shard model\n",
    "\n",
    "def remove_index(lst, idx):\n",
    "    return lst[:idx] + lst[idx+1:]\n",
    "\n",
    "dropped_cat_models = remove_index(shard_models, 0)\n",
    "\n",
    "overall, per_class = evaluate_ensemble(dropped_cat_models, full_test_loader, class_names, device)\n",
    "\n",
    "print(f\"SISA Ensemble Accuracy: {overall:.2f}%\\n\")\n",
    "print(\"Class-by-Class Accuracy:\")\n",
    "for cls, acc in per_class.items():\n",
    "    print(f\"{cls}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce36712",
   "metadata": {},
   "source": [
    "### Retrain Single Shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "949ae27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DroppedShardDataset(Dataset):\n",
    "    def __init__(self, shard_path, transform=None, drop_class=None):\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "\n",
    "        shard_path = Path(shard_path)\n",
    "\n",
    "        # Load samples\n",
    "        for cls_folder in shard_path.iterdir():\n",
    "            if cls_folder.is_dir():\n",
    "                cls_name = cls_folder.name\n",
    "                # Skip filtered class\n",
    "                if drop_class is not None and cls_name == drop_class:\n",
    "                    continue\n",
    "\n",
    "                for img in cls_folder.glob(\"*.jpg\"):\n",
    "                    self.samples.append((img, cls_name))\n",
    "                for img in cls_folder.glob(\"*.jpeg\"):\n",
    "                    self.samples.append((img, cls_name))\n",
    "                for img in cls_folder.glob(\"*.png\"):\n",
    "                    self.samples.append((img, cls_name))\n",
    "\n",
    "        # Rebuild class_to_idx after dropping\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(sorted({c for _, c in self.samples}))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ab16219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_dataset = DroppedShardDataset(\"shards/shard_0\", transform=transform, drop_class=\"cat\")\n",
    "loader = DataLoader(dropped_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "73ad7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_shard(dataloader,\n",
    "    epochs=100,\n",
    "    lr=1e-4,\n",
    "    device=\"mps\",\n",
    "    \n",
    "):\n",
    "    start = time.time()\n",
    "    # Build model\n",
    "    model = get_model()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for imgs, labels in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels_idx = torch.tensor([class_to_idx[lbl] for lbl in labels], dtype=torch.long).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels_idx)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Shard Training Time: {end - start:.5f} seconds\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2df37e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shard Training Time: 36.28261 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(51.283018867924525,\n",
       " {'cat': 0.0, 'dog': 70.44444274902344, 'horse': 80.55555725097656})"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrain_model = retrain_shard(loader)\n",
    "\n",
    "full_path = \"my_models/retrained_model_0.pt\"\n",
    "torch.save(retrain_model.state_dict(), full_path)\n",
    "\n",
    "model1 = [retrain_model]\n",
    "evaluate_ensemble(model1, full_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f863080e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SISA Ensemble Accuracy: 49.51%\n",
      "\n",
      "Class-by-Class Accuracy:\n",
      "cat: 0.71%\n",
      "dog: 45.11%\n",
      "horse: 100.00%\n"
     ]
    }
   ],
   "source": [
    "shard_models[0] = model\n",
    "\n",
    "overall, per_class = evaluate_ensemble(shard_models, full_test_loader, class_names, device)\n",
    "\n",
    "print(f\"SISA Ensemble Accuracy: {overall:.2f}%\\n\")\n",
    "print(\"Class-by-Class Accuracy:\")\n",
    "for cls, acc in per_class.items():\n",
    "    print(f\"{cls}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556b0516",
   "metadata": {},
   "source": [
    "# Full Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3d984a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Training Time: 30.06417 seconds\n",
      "Epoch 1/5, Loss: 1.3612\n",
      "Full model accuracy: 28.70%\n",
      "Epoch Training Time: 59.49050 seconds\n",
      "Epoch 2/5, Loss: 1.0335\n",
      "Full model accuracy: 44.82%\n",
      "Epoch Training Time: 89.44748 seconds\n",
      "Epoch 3/5, Loss: 0.8667\n",
      "Full model accuracy: 62.52%\n",
      "Epoch Training Time: 119.59852 seconds\n",
      "Epoch 4/5, Loss: 0.7210\n",
      "Full model accuracy: 65.69%\n",
      "Epoch Training Time: 148.99872 seconds\n",
      "Epoch 5/5, Loss: 0.5715\n",
      "Full model accuracy: 82.52%\n",
      "Total Training Time: 148.99872 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "num_classes = len(full_dataset.class_to_idx)\n",
    "\n",
    "model_full = models.resnet18(weights=None)\n",
    "model_full.fc = nn.Linear(model_full.fc.in_features, num_classes)\n",
    "model_full = model_full.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_full.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_full.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, labels in full_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_full(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    model_full.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in full_test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model_full(imgs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Epoch Training Time: {end - start:.5f} seconds\")\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(full_loader):.4f}\")\n",
    "    print(f\"Full model accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Total Training Time: {end - start:.5f} seconds\")\n",
    "\n",
    "# full_path = \"my_models/full_model.pt\"\n",
    "# torch.save(model_full.state_dict(), full_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
