{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef2b550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)            # Python random\n",
    "    np.random.seed(seed)         # NumPy\n",
    "    torch.manual_seed(seed)      # CPU seed\n",
    "\n",
    "    # For GPU (CUDA)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # For MPS (Apple Silicon)\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch.mps.manual_seed(seed)\n",
    "\n",
    "    # Make CuDNN deterministic (if using CUDA)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6ae71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FullDataset(Dataset):\n",
    "    def __init__(self, shards_dir, transform=None):\n",
    "        \"\"\"\n",
    "        shards_dir: path to the parent folder containing all shards\n",
    "        transform: torchvision transforms\n",
    "        \"\"\"\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        shards_dir = Path(shards_dir)\n",
    "\n",
    "        # iterate all shards and all class folders\n",
    "        for shard_folder in shards_dir.iterdir():\n",
    "            if shard_folder.is_dir():\n",
    "                for class_folder in shard_folder.iterdir():\n",
    "                    if class_folder.is_dir():\n",
    "                        for img_path in class_folder.iterdir():\n",
    "                            if img_path.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "                                # store (path, class_name)\n",
    "                                self.samples.append((img_path, class_folder.name))\n",
    "\n",
    "        # build class->index mapping\n",
    "        class_names = sorted({cls for _, cls in self.samples})\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label_idx = self.class_to_idx[label]\n",
    "        return img, label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9fc5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3  # your dataset\n",
    "\n",
    "def get_model():\n",
    "    set_seed(42)\n",
    "    model = models.resnet18(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9452f193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 models:\n",
      "Model 0: <class 'torchvision.models.resnet.ResNet'>\n",
      "Model 1: <class 'torchvision.models.resnet.ResNet'>\n",
      "Model 2: <class 'torchvision.models.resnet.ResNet'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Folder containing your model files\n",
    "model_folder = Path(\"my_models\")\n",
    "\n",
    "# List all .pt files starting with 'model_'\n",
    "model_files = sorted(model_folder.glob(\"model_*.pt\"))\n",
    "\n",
    "# List to store loaded models\n",
    "models_essemble = []\n",
    "\n",
    "for file in model_files:\n",
    "    model = get_model()  # initialize architecture\n",
    "    state_dict = torch.load(file, map_location=device)  # load the saved weights\n",
    "    model.load_state_dict(state_dict)  # load weights into model\n",
    "    models_essemble.append(model) \n",
    "\n",
    "print(f\"Loaded {len(models_essemble)} models:\")\n",
    "for i, m in enumerate(models_essemble):\n",
    "    print(f\"Model {i}: {type(m)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f67a8124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "set_seed(42)\n",
    "full_dataset = FullDataset(shards_dir=\"shards\", transform=transform)\n",
    "full_test_loader = DataLoader(full_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "233e6a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def ensemble_predict(models, input_tensor, device):\n",
    "    \"\"\"\n",
    "    models: list of shard models\n",
    "    input_tensor: batch of images (already on device)\n",
    "    returns: ensemble predictions (argmax over average logits)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        outputs = []\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            model.to(device)\n",
    "            outputs.append(model(input_tensor))\n",
    "        avg_output = sum(outputs)\n",
    "        # avg_output = sum(outputs) / len(outputs)\n",
    "        preds = avg_output.argmax(dim=1)\n",
    "    return preds\n",
    "\n",
    "def evaluate_ensemble(shard_models, test_loader, class_names, device):\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    # overall accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # class-wise tracking\n",
    "    class_correct = torch.zeros(num_classes)\n",
    "    class_total   = torch.zeros(num_classes)\n",
    "\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = ensemble_predict(shard_models, imgs, device)\n",
    "\n",
    "        # overall accuracy\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # class-wise accuracy\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i].item()\n",
    "            class_total[label] += 1\n",
    "            if preds[i].item() == label:\n",
    "                class_correct[label] += 1\n",
    "\n",
    "    # overall accuracy\n",
    "    overall_acc = 100 * correct / total\n",
    "\n",
    "    # per-class accuracy\n",
    "    class_acc = {}\n",
    "    for i in range(num_classes):\n",
    "        acc = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
    "        class_acc[class_names[i]] = acc.item()\n",
    "\n",
    "    return overall_acc, class_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22b017ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SISA Ensemble Accuracy: 67.77%\n",
      "\n",
      "Class-by-Class Accuracy:\n",
      "cat: 48.71%\n",
      "dog: 76.00%\n",
      "horse: 77.56%\n"
     ]
    }
   ],
   "source": [
    "class_names = sorted([p.name for p in Path(\"shards/shard_0\").iterdir() if p.is_dir()])\n",
    "overall, per_class = evaluate_ensemble(models_essemble, full_test_loader, class_names, device)\n",
    "\n",
    "print(f\"SISA Ensemble Accuracy: {overall:.2f}%\\n\")\n",
    "print(\"Class-by-Class Accuracy:\")\n",
    "for cls, acc in per_class.items():\n",
    "    print(f\"{cls}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9e939c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrained_model = get_model()\n",
    "state_dict = torch.load(\"my_models/retrained_model_0.pt\", map_location=device)  # load the saved weights\n",
    "retrained_model.load_state_dict(state_dict)  # load weights into model\n",
    "models_essemble[0] = retrained_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f73c907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SISA Ensemble Accuracy: 57.85%\n",
      "\n",
      "Class-by-Class Accuracy:\n",
      "cat: 3.76%\n",
      "dog: 88.78%\n",
      "horse: 78.00%\n"
     ]
    }
   ],
   "source": [
    "class_names = sorted([p.name for p in Path(\"shards/shard_0\").iterdir() if p.is_dir()])\n",
    "overall, per_class = evaluate_ensemble(models_essemble, full_test_loader, class_names, device)\n",
    "\n",
    "print(f\"SISA Ensemble Accuracy: {overall:.2f}%\\n\")\n",
    "print(\"Class-by-Class Accuracy:\")\n",
    "for cls, acc in per_class.items():\n",
    "    print(f\"{cls}: {acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
